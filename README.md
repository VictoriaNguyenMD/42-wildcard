<!-- ABOUT -->
## What is Wildcard?

<!-- BACKGROUND INFORMATION -->
## Introduction to Web Scraping in Healthcare 

The Internet stores a massive amount of information that can be extracted and analyzed. The process of obtainig this data from websites is known as web scraping. Web scraping can be done manually but it is most often performed via an automated process implemented using a bot or web crawler.

In the context of healthcare, most of what happens occurs outside the doctor's office. In fact, we are in a doctor's office for only a fraction of our life. According to the [2016 Physician Compensation Report](https://www.medscape.com/features/slideshow/compensation/2016/public/overview?src=wnl_physrep_160401_mscpedit&uac=232148CZ&impID=1045700&faf=1), doctors spend an average of 13-16 minutes with each patient, which is minimal compared to our lifespan.

As a result, web scraping is a way to quickly obtain data from people, such as customer feedback, potential suicidial ideations, and potential outbreaks. One Canadian company, BlueDot, using web scraping to detect the coronavirus outbreak several days before it was initially announced by the World Health Organization (WHO) and Centers for Disease Control and Prevention (CDC). In particular,this artificial intelligence (AI) company scours ["foreign-language news reports, animal and plant disease networks, and official proclamations"](https://www.wired.com/story/ai-epidemiologist-wuhan-public-health-warnings/) to provide infectious disease warnings to you.

Twitter, amongst many websites, is an excellent platform to display one's opinion toward a subject in an unbiased, natural manner. Since this social media platform is easy to access and public, it is a gold mine for extracting data, especially in terms of surveying public opinion about a particular healthcare product. 

In this project, we will scrape Twitter to create a tweet visualization and sentiment analysis to analyze healthcare-related Tweets using Python. 

## Utilizing a Twitter Scraper to Analyze 

In order to start scraping information from Twitter, you need a tool that enables Python to communicate with the Twitter platform. There are many packages and libraries that can bridge the conenction from code to the plaftform, but two particular tools in mind are BeautifulSoup and Tweepy. These tools are useful for webscraping and can extract tweets. 

The particular library that we are going to use for this product is Tweepy. This library is:
1. Easy-to-use
2. Has access to Twitter API
3. Can extract tweets real-time

<!-- PROJECT OUTLINE -->
## Project Outline: 

**1. Stream Live Tweets**

**2. Cursor and Pagination**

**3. Analyzing Tweet Data**

**4. Visualizing Tweet Data**

**5. Sentiment Analysis**

<!-- GETTING STARTED -->
## Getting Started

### Clone
`git clone 

### Set-Up

<!-- USAGE EXAMPLES -->
## Usage

<!-- CONTRIBUTING -->
## Contributing
Contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

#### References
1. [Web Scraping](https://en.wikipedia.org/wiki/Web_scraping)
2. [Tweet Visualization and Sentiment Analysis](https://www.youtube.com/watch?v=1gQ6uG5Ujiw)
